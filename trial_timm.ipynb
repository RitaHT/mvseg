{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "This is a practice notebook for Rita. \n",
    "Since no GPU, training on Colab: https://colab.research.google.com/drive/1Lp5xPuN4hG4n2LNZp44G9CBzC-fqYC7Q?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rita/anaconda3/envs/hfenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import nibabel as nib #for reading .nii.gz format MRI files\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import monai\n",
    "from monai.data import CacheDataset, DataLoader, CSVDataset\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd, EnsureChannelFirst,\n",
    "    Activations,\n",
    "    AsDiscreted, AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged, LoadImage,\n",
    "    SplitDimd, SplitDim,\n",
    "    Orientationd,\n",
    "    Randomizable,\n",
    "    Resized, Resize,\n",
    "    CenterSpatialCropd, CenterSpatialCrop,\n",
    "    ScaleIntensityd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    ToTensord,ToTensor,\n",
    "    NormalizeIntensityd, NormalizeIntensity,\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "#import cv2 #opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# default model with classifier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m m0 \u001b[38;5;241m=\u001b[39m \u001b[43mtimm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmobilevit_xxs.cvnets_in1k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(m0)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[38;5;241m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable\u001b[38;5;241m=\u001b[39mscriptable, exportable\u001b[38;5;241m=\u001b[39mexportable, no_jit\u001b[38;5;241m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:625\u001b[0m, in \u001b[0;36mmobilevit_xxs\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@register_model\u001b[39m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmobilevit_xxs\u001b[39m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ByobNet:\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_mobilevit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilevit_xxs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:548\u001b[0m, in \u001b[0;36m_create_mobilevit\u001b[0;34m(variant, cfg_variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_mobilevit\u001b[39m(variant, cfg_variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mByobNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflatten_sequential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:418\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m num_classes_pretrained \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 418\u001b[0m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43min_chans\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:158\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pretrained_cfg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid pretrained config, cannot load weights. Use `pretrained=False` for random init.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m load_from, pretrained_loc \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_pretrained_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_from \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    160\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading pretrained weights from state dict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:63\u001b[0m, in \u001b[0;36m_resolve_pretrained_source\u001b[0;34m(pretrained_cfg)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _USE_OLD_CACHE:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# prioritized old cached weights if exists and env var enabled\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     old_cache_valid \u001b[38;5;241m=\u001b[39m check_cached_file(pretrained_url) \u001b[38;5;28;01mif\u001b[39;00m pretrained_url \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m old_cache_valid \u001b[38;5;129;01mand\u001b[39;00m hf_hub_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mhas_hf_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnecessary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# hf-hub available as alternate weight source in default_cfg\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     load_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf-hub\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m     pretrained_loc \u001b[38;5;241m=\u001b[39m hf_hub_id\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_hub.py:111\u001b[0m, in \u001b[0;36mhas_hf_hub\u001b[0;34m(necessary)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_hf_hub\u001b[39m(necessary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_hf_hub \u001b[38;5;129;01mand\u001b[39;00m necessary:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# if no HF Hub module installed, and it is necessary to continue, raise error\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _has_hf_hub\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`."
     ]
    }
   ],
   "source": [
    "# default model with classifier\n",
    "m0 = timm.create_model(\"mobilevit_xxs.cvnets_in1k\", pretrained=True)\n",
    "print(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/rita/anaconda3/envs/hfenv/lib/python312.zip', '/Users/rita/anaconda3/envs/hfenv/lib/python3.12', '/Users/rita/anaconda3/envs/hfenv/lib/python3.12/lib-dynload', '', '/Users/rita/anaconda3/envs/hfenv/lib/python3.12/site-packages', '/Users/rita/anaconda3/envs/hfenv/lib/python3.12/site-packages/huggingface_hub']\n"
     ]
    }
   ],
   "source": [
    "import sys; \n",
    "#print(sys.executable) #/Users/rita/anaconda3/envs/hfenv/bin/python\n",
    "print(sys.path) \n",
    "#sys.path.append('/Users/rita/anaconda3/envs/hfenv/lib/python3.12/site-packages/huggingface_hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'num_chs': 32, 'reduction': 2, 'module': 'stages.0', 'stage': 1, 'index': 0}, {'num_chs': 64, 'reduction': 4, 'module': 'stages.1', 'stage': 2, 'index': 1}, {'num_chs': 128, 'reduction': 8, 'module': 'stages.2', 'stage': 3, 'index': 2}, {'num_chs': 192, 'reduction': 16, 'module': 'stages.3', 'stage': 4, 'index': 3}, {'num_chs': 256, 'reduction': 32, 'module': 'final_conv', 'stage': 5, 'index': 4}]\n"
     ]
    }
   ],
   "source": [
    "m0 = timm.create_model(\"mobilevitv2_050\", features_only=True)\n",
    "#print(m0.feature_info.get_dicts())\n",
    "#mobilevit_xxs\n",
    "#[{'num_chs': 16, 'reduction': 2, 'module': 'stages.0', 'stage': 1, 'index': 0}, \n",
    "# {'num_chs': 24, 'reduction': 4, 'module': 'stages.1', 'stage': 2, 'index': 1}, \n",
    "# {'num_chs': 48, 'reduction': 8, 'module': 'stages.2', 'stage': 3, 'index': 2}, \n",
    "# {'num_chs': 64, 'reduction': 16, 'module': 'stages.3', 'stage': 4, 'index': 3}, \n",
    "# {'num_chs': 320, 'reduction': 32, 'module': 'final_conv', 'stage': 5, 'index': 4}]\n",
    "\n",
    "#mobilevitv2_050\n",
    "#[{'num_chs': 32, 'reduction': 2, 'module': 'stages.0', 'stage': 1, 'index': 0}, \n",
    "# {'num_chs': 64, 'reduction': 4, 'module': 'stages.1', 'stage': 2, 'index': 1}, \n",
    "# {'num_chs': 128, 'reduction': 8, 'module': 'stages.2', 'stage': 3, 'index': 2}, \n",
    "# {'num_chs': 192, 'reduction': 16, 'module': 'stages.3', 'stage': 4, 'index': 3}, \n",
    "# {'num_chs': 256, 'reduction': 32, 'module': 'final_conv', 'stage': 5, 'index': 4}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "# Loop through the model's layers and print their weights\n",
    "i = 0\n",
    "for name, param in m0.named_parameters():\n",
    "    #print(f\"Layer: {name} | Shape: {param.shape} \") #| Values: {param[:2]}\")  # printing only first 2 values for brevity\n",
    "    i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want Penultimate Layer Features (Pre-Classifier Features), not classification\n",
    "# this one ends with:\n",
    "#   (fc): Identity()\n",
    "#   (flatten): Identity()\n",
    "m1 = timm.create_model(\n",
    "    \"mobilevit_xxs.cvnets_in1k\", \n",
    "    pretrained=True, \n",
    "    num_classes=0, \n",
    "    global_pool='')\n",
    "\n",
    "\n",
    "# pretrained weights need <batch B, 3 channels, H, W>:\n",
    "# ex. (1, 3, 224, 224) -> torch.Size([1,1000]) if classifier\n",
    "# ex.                  -> torch.Size([1, 320, 7, 7]) if preclassifier (no classifier head & pooling)\n",
    "# ex. (1, 3, 96, 96)   -> torch.Size([1, 320, 3, 3]) if classifier\n",
    "x = torch.randn(1, 3, 96, 96) \n",
    "o = m1(x)  \n",
    "#print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileViTv2\n",
    "# This one with LinearTransformerBlock(...), LinearSelfAttention(...) classes \n",
    "#   crop_pct=0.888?\n",
    "m2 = timm.create_model(\n",
    "    \"mobilevitv2_050.cvnets_in1k\", \n",
    "    pretrained=True, \n",
    "    num_classes=0, \n",
    "    global_pool='')\n",
    "\n",
    "# pretrained weights need <batch B, 3 channels, H, W>:\n",
    "# ex. (1, 3, 224, 224) -> torch.Size([1,1000]) if classifier\n",
    "# ex.                  -> torch.Size([1, 256, 8, 8]) if preclassifier (no classifier head & pooling)\n",
    "# ex. (1, 3, 96, 96)   -> torch.Size([1, 256, 4, 4]) if classifier\n",
    "x = torch.randn(1, 3, 224, 224) \n",
    "o = m2(x)\n",
    "print(o.shape)  \n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/rita/Desktop/harini_lab/\")\n",
    "cwd = os.getcwd() #/Users/rita/Desktop/\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'PROSTATEx/Files/lesions/'\n",
    "csvFile_image = pd.read_csv(os.path.join(file_dir,'image_list.csv')) #(201,2)\n",
    "csvFile_score = pd.read_csv(os.path.join(file_dir,'prostatex_classes.csv')) #(299,3)\n",
    "\n",
    "img_dir_ADC = os.path.join(file_dir, 'Images/ADC') #PROSTATEx/Files/lesions/Images/ADC/X.nii.gz\n",
    "label_dir_ADC = os.path.join(file_dir, 'Masks/ADC') #PROSTATEx/Files/lesions/Masks/ADC/X.nii.gz\n",
    "\n",
    "img_dir_T2 = os.path.join(file_dir, 'Images/T2') #PROSTATEx/Files/lesions/Images/T2/X.nii.gz\n",
    "label_dir_T2 = os.path.join(file_dir, 'Masks/T2') #PROSTATEx/Files/lesions/Masks/ADC/X.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csvFile_score[\"T2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in listdir(label_dir_ADC):\n",
    "    # ex. ProstateX-0006-Finding1-ep2d_diff_tra_DYNDIST_ADC_ROI.nii.gz\n",
    " #   chID = i[0:23]\n",
    "#    print(chID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvFile_score[\"ID\"] = csvFile_score[\"ID\"].str.replace('_', '-', n=1)\n",
    "csvFile_score[\"ADC\"] = label_dir_ADC + '/' + csvFile_score[\"ADC\"]\n",
    "csvFile_score[\"T2\"] = label_dir_T2 + '/' + csvFile_score[\"T2\"]\n",
    "print(csvFile_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to create dataset (IP)\n",
    "X_train_ADC = [] #len = 201\n",
    "X_train_T2 = []\n",
    "\n",
    "#how to deal with clinical significant & Gleason score?\n",
    "#could have multiple lesions mask for one patient?\n",
    "#   check how standard dataset organized them?\n",
    "y_mask_ADC = []\n",
    "y_mask_T2 = []\n",
    "\n",
    "for i in range(len(csvFile_image)): \n",
    "    img_filename_ADC, img_filename_T2 = csvFile_image.iloc[i]\n",
    "    img_complete_path_ADC = os.path.join(img_dir_ADC, img_filename_ADC) + '.nii.gz'\n",
    "    img_ADC = nib.load(img_complete_path_ADC)\n",
    "    imgdata_ADC = img_ADC.get_fdata() #(84, 128, 19)\n",
    "\n",
    "    img_complete_path_T2 = os.path.join(img_dir_T2, img_filename_T2) + '.nii.gz'\n",
    "    img_T2 = nib.load(img_complete_path_T2)\n",
    "    imgdata_T2 = img_T2.get_fdata() #(384, 384, 19)\n",
    "\n",
    "    # 2D network\n",
    "    # or should I just use the middle 3 slices (mask at 13~17) for each?\n",
    "    num_slice = imgdata_ADC.shape[2]\n",
    "    for i in range(0, num_slice-3, 3): #0~16, step=3: 0,3,6,9,12,15\n",
    "        slice_ADC = imgdata_ADC[:,:,i:i+3]\n",
    "        X_train_ADC.append(slice_ADC)\n",
    "\n",
    "        slice_T2 = imgdata_T2[:,:,i:i+3]\n",
    "        X_train_T2.append(slice_T2)\n",
    "    #below is the filename I changed to match csv \n",
    "    #all csv items are added .nii.gz at the end for better MONAI reading\n",
    "    # ADC:\n",
    "    #ProstateX-0025_ep2d_diff_tra_7a.nii.gz ->7\n",
    "    #ProstateX-0113_ep2d_diff_tra_9.nii.gz -> 10\n",
    "    #ProstateX-0203_diffusie-3ProstateX-0203_diffusie-3Scan-4bval_fs_7.niiScan-4bval_fs_7.nii\n",
    "    #-> ProstateX-0203_diffusie-3Scan-4bval_fs_7.nii.gz\n",
    "    # T2:\n",
    "    #ProstateX-0128_t2_tse_tra_5.nii -> _5.nii.gz: nib.load(), nib.save()\n",
    "    # Missing:\n",
    "    # 0052, 0080, 0138, \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T2[5].shape #201*6=1217???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvFile_image['ADC'] = csvFile_image['ADC'] + '.nii.gz'\n",
    "#csvFile_image['T2'] = csvFile_image['T2'] + '.nii.gz'\n",
    "csvFile_image['ADC'] = img_dir_ADC + '/' + csvFile_image['ADC'] \n",
    "csvFile_image['T2'] = img_dir_T2 + '/' + csvFile_image['T2']\n",
    "\n",
    "\n",
    "print(csvFile_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'PROSTATEx_Classes.csv'\n",
    "csvFile_score.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.add_subplot(2, 2, 1); plt.imshow(X_train_ADC[7][:,:,1].T, cmap='Greys_r'); plt.title(\"Example ADC Image\")\n",
    "fig.add_subplot(2, 2, 2); plt.imshow(X_train_T2[7][:,:,1].T, cmap='Greys_r'); plt.title(\"Example T2 Image\")\n",
    "print(X_train_T2[7].shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "train_pkl_ADC = open('train_multi_ADC.pkl','wb')\n",
    "pickle.dump(X_train_ADC, train_pkl_ADC, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "train_pkl_ADC.close()\n",
    "train_pkl_T2 = open('train_multi_T2.pkl','wb')\n",
    "pickle.dump(X_train_T2, train_pkl_T2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "train_pkl_T2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example images\n",
    "img_filename_ADC, img_filename_T2 = csvFile_image.iloc[10] #change for different imgs\n",
    "\n",
    "img_complete_path_ADC = os.path.join(img_dir_ADC, img_filename_ADC) + '.nii.gz'\n",
    "img_ADC = nib.load(img_complete_path_ADC)\n",
    "imgdata_ADC = img_ADC.get_fdata() #(84, 128, 19)\n",
    "\n",
    "slice_ADC = imgdata_ADC[:,:,13:16] #(mask at 13~17) #(84,128)\n",
    "plt.imshow(slice_ADC[:,:,2].T, cmap='Greys_r'); plt.title(\"Example ADC Image\")\n",
    "\n",
    "img_complete_path_T2 = os.path.join(img_dir_T2, img_filename_T2) + '.nii.gz'\n",
    "img_T2 = nib.load(img_complete_path_T2)\n",
    "imgdata_T2 = img_T2.get_fdata() #(384, 384, 19)\n",
    "\n",
    "slice_T2 = imgdata_T2[:,:,13:16] #changed\n",
    "#plt.imshow(slice_T2[:,:,2].T, cmap='Greys_r'); plt.title(\"Example T2 Image\")\n",
    "print(slice_ADC.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.save('ex_multi_slice_ADC', slice_ADC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile_label['chID'] = csvFile_label['ID'].str[0:14]\n",
    "csvFile_image['chID'] = csvFile_image_ori['ADC'].str[0:14] #201\n",
    "\n",
    "print(csvFile_image)\n",
    "test = pd.merge(csvFile_image, csvFile_label, on='chID')\n",
    "output_file = 'lesions_total.csv'\n",
    "test.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(csvFile_image, csvFile_label, on='chID')\n",
    "output_file = 'lesions_total.csv'\n",
    "test.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load example image\n",
    "slice_ADC = np.load('ex_multi_slice_ADC.npy')[:,:,1]\n",
    "slice_T2 = np.load('ex_multi_slice_T2.npy')[:,:,1]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "#fig.add_subplot(2, 2, 1); plt.imshow(slice_T2[:,:,1].T, cmap='Greys_r'); plt.title(\"Example T2 Image\")\n",
    "fig.add_subplot(2, 2, 1); plt.imshow(slice_T2.T, cmap='Greys_r'); plt.title(\"Example T2 Image\")\n",
    "print(slice_T2.shape) \n",
    "#fig.add_subplot(2, 2, 2); plt.imshow(slice_ADC[:,:,1].T, cmap='Greys_r'); plt.title(\"Example ADC Image\")\n",
    "fig.add_subplot(2, 2, 2); plt.imshow(slice_ADC.T, cmap='Greys_r'); plt.title(\"Example ADC Image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rita/Desktop/harini_lab\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/rita/Desktop/harini_lab/\")\n",
    "cwd = os.getcwd() #/Users/rita/Desktop/\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "f = open('PROSTATEx/train_multi_ADC.pkl', 'rb')\n",
    "X_ADC = pickle.load(f)\n",
    "f.close()\n",
    "f = open('PROSTATEx/train_multi_T2.pkl', 'rb')\n",
    "X_T2 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.add_subplot(2, 2, 1); plt.imshow(X_ADC[7][:,:,1].T, cmap='Greys_r'); plt.title(\"Example ADC Image\")\n",
    "fig.add_subplot(2, 2, 2); plt.imshow(X_T2[7][:,:,1].T, cmap='Greys_r'); plt.title(\"Example T2 Image\")\n",
    "print(X_T2[7].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_ADC = X_ADC[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rita/Desktop/harini_lab\n"
     ]
    }
   ],
   "source": [
    "#copy from above\n",
    "os.chdir(\"/Users/rita/Desktop/harini_lab/\")\n",
    "cwd = os.getcwd() #/Users/rita/Desktop/\n",
    "print(cwd)\n",
    "\n",
    "file_dir = 'PROSTATEx/Files/lesions/'\n",
    "#csvFilePath_image = os.path.join(file_dir,'image_list.csv')\n",
    "#csvFilePath_label = os.path.join(file_dir,'prostatex_classes.csv')\n",
    "csvFilePath_total = os.path.join(file_dir,'lesions_total.csv')\n",
    "\n",
    "#csvFile_image = pd.read_csv(csvFilePath_image)\n",
    "#csvFile_label = pd.read_csv(csvFilePath_label)\n",
    "csvFile_total = pd.read_csv(csvFilePath_total) #(299,8)\n",
    "\n",
    "img_dir_ADC = os.path.join(file_dir, 'Images/ADC') #lesions/Images/ADC/X.nii.gz\n",
    "img_dir_T2 = os.path.join(file_dir, 'Images/T2') #lesions/Images/T2/X.nii.gz\n",
    "label_dir_ADC = os.path.join(file_dir, 'Masks/ADC') #PROSTATEx/Files/lesions/Masks/ADC/X.nii.gz\n",
    "label_dir_T2 = os.path.join(file_dir, 'Masks/T2') #PROSTATEx/Files/lesions/Masks/T2/X.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load by MONAI\n",
    "\n",
    "# create transform in MONAI format\n",
    "# can also use transform from timm???\n",
    "''' \n",
    "Compose(\n",
    "    Resize(size=288, interpolation=bicubic, max_size=None, antialias=True)\n",
    "    CenterCrop(size=(256, 256))\n",
    "    ToTensor()\n",
    "    Normalize(mean=tensor([0., 0., 0.]), std=tensor([1., 1., 1.]))\n",
    ")\n",
    "'''\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ADC_image\", \"ADC_mask\"],channel_dim=2), #default NibelReader #[84, 128, 19]\n",
    "        EnsureChannelFirstd(keys=[\"ADC_image\", \"ADC_mask\"]), #[19, 84, 128]\n",
    "        #SplitDimd(keys=[\"ADC_image\", \"ADC_mask\"], dim = 0), #leave out the splitting??\n",
    "        Resized(keys=[\"ADC_image\", \"ADC_mask\"], spatial_size=(288,288), anti_aliasing=True), #[1, 288, 288]\n",
    "        CenterSpatialCropd(keys=[\"ADC_image\", \"ADC_mask\"], roi_size=(256,256)), #[1, 256, 256]\n",
    "        #ScaleIntensityd(keys=\"image\"),\n",
    "        #EnsureTyped(keys=\"image\"),\n",
    "        ToTensord(keys=[\"ADC_image\", \"ADC_mask\"]),\n",
    "        NormalizeIntensityd(keys=[\"ADC_image\"]),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"ADC_image\", \"ADC_mask\"],channel_dim=2), #default NibelReader #[84, 128, 19]\n",
    "        EnsureChannelFirstd(keys=[\"ADC_image\", \"ADC_mask\"]), #[1, 84, 128, 19]\n",
    "        Resized(keys=[\"ADC_image\", \"ADC_mask\"], spatial_size=(288,288), anti_aliasing=True), #mode='bicubic'??\n",
    "        CenterSpatialCropd(keys=[\"ADC_image\", \"ADC_mask\"], roi_size=(256,256)),\n",
    "        ToTensord(keys=[\"ADC_image\", \"ADC_mask\"]),\n",
    "        NormalizeIntensityd(keys=[\"ADC_image\"]),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               chID                       ID  Clinically Significant  \\\n",
      "0    ProstateX-0000  ProstateX-0000-Finding1                    True   \n",
      "1    ProstateX-0001  ProstateX-0001-Finding1                   False   \n",
      "2    ProstateX-0002  ProstateX-0002-Finding1                    True   \n",
      "3    ProstateX-0002  ProstateX-0002-Finding2                   False   \n",
      "4    ProstateX-0003  ProstateX-0003-Finding1                   False   \n",
      "..              ...                      ...                     ...   \n",
      "294  ProstateX-0201  ProstateX-0201-Finding1                    True   \n",
      "295  ProstateX-0202  ProstateX-0202-Finding1                    True   \n",
      "296  ProstateX-0202  ProstateX-0202-Finding2                   False   \n",
      "297  ProstateX-0203  ProstateX-0203-Finding1                    True   \n",
      "298  ProstateX-0203  ProstateX-0203-Finding2                    True   \n",
      "\n",
      "       Gleason Grade Group                                          ADC_image  \\\n",
      "0                        3  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "1                        1  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "2                        2  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "3                        1  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "4    No biopsy information  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "..                     ...                                                ...   \n",
      "294                      2  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "295                      4  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "296  No biopsy information  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "297                      2  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "298                      3  PROSTATEx/Files/lesions/Images/ADC/ProstateX-0...   \n",
      "\n",
      "                                              T2_image  \\\n",
      "0    PROSTATEx/Files/lesions/Images/T2/ProstateX-00...   \n",
      "1    PROSTATEx/Files/lesions/Images/T2/ProstateX-00...   \n",
      "2    PROSTATEx/Files/lesions/Images/T2/ProstateX-00...   \n",
      "3    PROSTATEx/Files/lesions/Images/T2/ProstateX-00...   \n",
      "4    PROSTATEx/Files/lesions/Images/T2/ProstateX-00...   \n",
      "..                                                 ...   \n",
      "294  PROSTATEx/Files/lesions/Images/T2/ProstateX-02...   \n",
      "295  PROSTATEx/Files/lesions/Images/T2/ProstateX-02...   \n",
      "296  PROSTATEx/Files/lesions/Images/T2/ProstateX-02...   \n",
      "297  PROSTATEx/Files/lesions/Images/T2/ProstateX-02...   \n",
      "298  PROSTATEx/Files/lesions/Images/T2/ProstateX-02...   \n",
      "\n",
      "                                              ADC_mask  \\\n",
      "0    PROSTATEx/Files/lesions/Masks/ADC/ProstateX-00...   \n",
      "1    PROSTATEx/Files/lesions/Masks/ADC/ProstateX-00...   \n",
      "2    PROSTATEx/Files/lesions/Masks/ADC/ProstateX-00...   \n",
      "3    PROSTATEx/Files/lesions/Masks/ADC/ProstateX-00...   \n",
      "4    PROSTATEx/Files/lesions/Masks/ADC/ProstateX-00...   \n",
      "..                                                 ...   \n",
      "294  PROSTATEx/Files/lesions/Masks/ADC/ProstateX-02...   \n",
      "295  PROSTATEx/Files/lesions/Masks/ADC/ProstateX-02...   \n",
      "296  PROSTATEx/Files/lesions/Masks/ADC/ProstateX-02...   \n",
      "297  PROSTATEx/Files/lesions/Masks/ADC/ProstateX-02...   \n",
      "298  PROSTATEx/Files/lesions/Masks/ADC/ProstateX-02...   \n",
      "\n",
      "                                               T2_mask  \n",
      "0    PROSTATEx/Files/lesions/Masks/T2/ProstateX-000...  \n",
      "1    PROSTATEx/Files/lesions/Masks/T2/ProstateX-000...  \n",
      "2    PROSTATEx/Files/lesions/Masks/T2/ProstateX-000...  \n",
      "3    PROSTATEx/Files/lesions/Masks/T2/ProstateX-000...  \n",
      "4    PROSTATEx/Files/lesions/Masks/T2/ProstateX-000...  \n",
      "..                                                 ...  \n",
      "294  PROSTATEx/Files/lesions/Masks/T2/ProstateX-020...  \n",
      "295  PROSTATEx/Files/lesions/Masks/T2/ProstateX-020...  \n",
      "296  PROSTATEx/Files/lesions/Masks/T2/ProstateX-020...  \n",
      "297  PROSTATEx/Files/lesions/Masks/T2/ProstateX-020...  \n",
      "298  PROSTATEx/Files/lesions/Masks/T2/ProstateX-020...  \n",
      "\n",
      "[299 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "total_dataset = CSVDataset(\n",
    "    src=csvFilePath_total,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "print(pd.DataFrame(total_dataset.data))\n",
    "# ADC_image: ProstateX-0000_ep2d_diff_tra_7.nii.gz   ADC_mask: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loader = DataLoader(total_dataset, batch_size=1, num_workers=4, pin_memory=True) #(299)\n",
    "train_loader = DataLoader(total_dataset, batch_size=1, num_workers=4, pin_memory=True) #(299)\n",
    "#shuffle=True??\n",
    "#val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "#val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the transformed image array\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    #plt.xlabel(dataset[i][\"subject_id\"]) #need this later?\n",
    "    plt.imshow(total_dataset[i][\"ADC_image\"][11,:,:].T, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = monai.visualize.matshow3d(monai.transforms.Orientation(\"SPL\")(total_dataset[2][\"ADC_mask\"]), every_n=1, figsize=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split image in training loop\n",
    "from monai.transforms.transform import Transform\n",
    "\n",
    "class SplitImageCustom(Transform):\n",
    "    def __init__(self, split_size: int = 3, dim: int = 1, keepdim: bool = True, update_meta=True) -> None:\n",
    "        self.dim = dim #assume ChannelFirst, and dim=0 is batchsize\n",
    "        self.keepdim = keepdim\n",
    "        self.update_meta = update_meta\n",
    "        self.split_size = split_size\n",
    "    def __call__(self, img: torch.Tensor) -> list[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Apply the transform to `img`.\n",
    "        \"\"\"\n",
    "        n_out = img.shape[self.dim] #img.shape[1]= 19 #[1, 19, 256, 256]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            outputs = list(torch.split(img, self.split_size, self.dim)) #6 * [1, 3, 256, 256]\n",
    "        else:\n",
    "            outputs = np.split(img, n_out//self.split_size, self.dim)\n",
    "        # check last item dimension (not checked for np.array yet)\n",
    "        if outputs[-1].shape[self.dim] != self.split_size:\n",
    "            outputs = outputs[:-1]\n",
    "        # put it back to a torch tensor of [batch_size, dim, h, w]: put it outside?\n",
    "        combined_tensor = torch.cat(outputs, dim=0)\n",
    "        return combined_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \"Image Embedding\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtimm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilevitv2_050.cvnets_in1k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#remove classifier\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#change number of input channels, cannot use pretrained weights?\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;66;03m#.to(device) \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m# \"Feature Map Extraction\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mmodel = timm.create_model(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m).to(device)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[38;5;241m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable\u001b[38;5;241m=\u001b[39mscriptable, exportable\u001b[38;5;241m=\u001b[39mexportable, no_jit\u001b[38;5;241m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:640\u001b[0m, in \u001b[0;36mmobilevitv2_050\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;129m@register_model\u001b[39m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmobilevitv2_050\u001b[39m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ByobNet:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_mobilevit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilevitv2_050\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:548\u001b[0m, in \u001b[0;36m_create_mobilevit\u001b[0;34m(variant, cfg_variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_mobilevit\u001b[39m(variant, cfg_variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mByobNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflatten_sequential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:418\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m num_classes_pretrained \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 418\u001b[0m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43min_chans\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:158\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pretrained_cfg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid pretrained config, cannot load weights. Use `pretrained=False` for random init.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m load_from, pretrained_loc \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_pretrained_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_from \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    160\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading pretrained weights from state dict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:63\u001b[0m, in \u001b[0;36m_resolve_pretrained_source\u001b[0;34m(pretrained_cfg)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _USE_OLD_CACHE:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# prioritized old cached weights if exists and env var enabled\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     old_cache_valid \u001b[38;5;241m=\u001b[39m check_cached_file(pretrained_url) \u001b[38;5;28;01mif\u001b[39;00m pretrained_url \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m old_cache_valid \u001b[38;5;129;01mand\u001b[39;00m hf_hub_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mhas_hf_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnecessary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# hf-hub available as alternate weight source in default_cfg\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     load_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf-hub\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m     pretrained_loc \u001b[38;5;241m=\u001b[39m hf_hub_id\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_hub.py:111\u001b[0m, in \u001b[0;36mhas_hf_hub\u001b[0;34m(necessary)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_hf_hub\u001b[39m(necessary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_hf_hub \u001b[38;5;129;01mand\u001b[39;00m necessary:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# if no HF Hub module installed, and it is necessary to continue, raise error\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _has_hf_hub\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`."
     ]
    }
   ],
   "source": [
    "# \"Image Embedding\"\n",
    "model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    "    num_classes=0, #remove classifier\n",
    "    in_chans = 3 #change number of input channels, cannot use pretrained weights?\n",
    ")#.to(device) \n",
    "\n",
    "'''\n",
    "# \"Feature Map Extraction\"\n",
    "model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ").to(device)\n",
    "\n",
    "# \"Image Classification\"\n",
    "model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k', \n",
    "    pretrained=True\n",
    ").to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model specific transforms (normalization, resize)\n",
    "#data_config = timm.data.resolve_model_data_config(m2)\n",
    "#transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "\n",
    "# torchvision transforms module takes PIL image with 3 channels, need to add lines\n",
    "pil_image = trans.ToPILImage()(slice_ADC) #(384, 384)\n",
    "x = transforms(pil_image).unsqueeze(0) #torch.Size([1, 3, 256, 256])\n",
    "print(\"x.shape = {}\".format(x.shape))\n",
    "output = m2(x) #list with len=5 tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try use wandb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(project=\"monai-brain-tumor-segmentation\")\n",
    "\n",
    "config = wandb.config\n",
    "config.seed = 0\n",
    "config.roi_size = [224, 224, 144]\n",
    "config.batch_size = 1\n",
    "config.num_workers = 4\n",
    "config.max_train_images_visualized = 20\n",
    "config.max_val_images_visualized = 20\n",
    "config.dice_loss_smoothen_numerator = 0\n",
    "config.dice_loss_smoothen_denominator = 1e-5\n",
    "config.dice_loss_squared_prediction = True\n",
    "config.dice_loss_target_onehot = False\n",
    "config.dice_loss_apply_sigmoid = True\n",
    "config.initial_learning_rate = 1e-4\n",
    "config.weight_decay = 1e-5\n",
    "config.max_train_epochs = 50\n",
    "config.validation_intervals = 1\n",
    "config.dataset_dir = \"./dataset/\"\n",
    "config.checkpoint_dir = \"./checkpoints\"\n",
    "config.inference_roi_size = (128, 128, 64)\n",
    "config.max_prediction_images_visualized = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define loss, optimizer\n",
    "https://colab.research.google.com/drive/1KD7Kvv2-sNCKvhygcWqJc4Lv1F73sbzQ#scrollTo=hu4Qj5P92ifH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    config.initial_learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "\n",
    "# create learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=config.max_train_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss\n",
    "#   as multi-label `DiceLoss` using the `monai.losses` API \n",
    "#   and the corresponding dice metrics using the `monai.metrics` API.\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "loss_function = DiceLoss(\n",
    "    smooth_nr=config.dice_loss_smoothen_numerator,\n",
    "    smooth_dr=config.dice_loss_smoothen_denominator,\n",
    "    squared_pred=config.dice_loss_squared_prediction,\n",
    "    to_onehot_y=config.dice_loss_target_onehot,\n",
    "    sigmoid=config.dice_loss_apply_sigmoid,\n",
    ")\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# use automatic mixed-precision to accelerate training\n",
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "#torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\")\n",
    "\n",
    "model.train()\n",
    "epoch_loss = 0\n",
    "\n",
    "batch_data = next(iter(train_loader)) #dictionary object, len=8\n",
    "inputs, labels = (\n",
    "    SplitImageCustom(dim = 1)(batch_data[\"ADC_image\"]),#.to(device), #[2, 19, 256, 256] -> [12, 3, 256, 256]\n",
    "    SplitImageCustom(dim = 1)(batch_data[\"ADC_mask\"]),#.to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.cuda.amp.autocast():\n",
    "outputs = model(inputs)\n",
    "    #loss = loss_function(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 32, 128, 128])\n",
      "torch.Size([6, 64, 64, 64])\n",
      "torch.Size([6, 128, 32, 32])\n",
      "torch.Size([6, 192, 16, 16])\n",
      "torch.Size([6, 256, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for item in outputs:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train (references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# official command: \n",
    "# check train.py\n",
    "./distributed_train.sh 4 /data/imagenet \n",
    "--model seresnet34 \n",
    "--sched cosine \n",
    "--epochs 150 \n",
    "--warmup-epochs 5 \n",
    "--lr 0.4 \n",
    "--reprob 0.5 \n",
    "--remode pixel \n",
    "--batch-size 256 \n",
    "--amp -j 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /timm/ has finetuning tutorial with its own Trainer object\n",
    "# https://huggingface.co/docs/transformers/main/en/training#finetune-with-trainer \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/main/en/training#finetune-with-trainer \n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref training loop w/ wandb:\n",
    "#https://colab.research.google.com/drive/1KD7Kvv2-sNCKvhygcWqJc4Lv1F73sbzQ#scrollTo=hu4Qj5P92ifH\n",
    "# check paper for their training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rita/anaconda3/envs/hfenv/lib/python3.12/site-packages/transformers/models/mobilevit/feature_extraction_mobilevit.py:28: FutureWarning: The class MobileViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use MobileViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from huggingface transformer git repo:\n",
    "# https://huggingface.co/docs/transformers/main/en/model_doc/mobilevitv2#transformers.MobileViTV2ForSemanticSegmentation \n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, MobileViTV2ForSemanticSegmentation, MobileViTForSemanticSegmentation, MobileViTFeatureExtractor\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = MobileViTFeatureExtractor.from_pretrained(\"apple/deeplabv3-mobilevit-xx-small\")\n",
    "model = MobileViTForSemanticSegmentation.from_pretrained(\"apple/deeplabv3-mobilevit-xx-small\")\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs) #SemanticSegmenterOutput(loss, logits, grad_fn, hidden_states, attentions)\n",
    "logits = outputs.logits #[1, 21, 32, 32]\n",
    "predicted_mask = logits.argmax(1).squeeze(0) #[32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "batch_data = next(iter(train_loader)) #dictionary object, len=8\n",
    "inputs, labels = (\n",
    "    SplitImageCustom(dim = 1)(batch_data[\"ADC_image\"]),#.to(device), #[2, 19, 256, 256] -> [12, 3, 256, 256]\n",
    "    SplitImageCustom(dim = 1)(batch_data[\"ADC_mask\"]),#.to(device),\n",
    ")\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss #23.6 until here\n",
    "#loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 21, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits #[6,21,16,16]\n",
    "predicted_mask = logits.argmax(1).squeeze(0) # [6,16,16]\n",
    "print(logits.shape)\n",
    "#plt.imshow(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x162a21220>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#checking\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mobilevitv2_model \u001b[38;5;241m=\u001b[39m \u001b[43mtimm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilevitv2_050.cvnets_in1k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[38;5;241m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable\u001b[38;5;241m=\u001b[39mscriptable, exportable\u001b[38;5;241m=\u001b[39mexportable, no_jit\u001b[38;5;241m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg_overlay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:640\u001b[0m, in \u001b[0;36mmobilevitv2_050\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;129m@register_model\u001b[39m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmobilevitv2_050\u001b[39m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ByobNet:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_mobilevit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilevitv2_050\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/mobilevit.py:548\u001b[0m, in \u001b[0;36m_create_mobilevit\u001b[0;34m(variant, cfg_variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_mobilevit\u001b[39m(variant, cfg_variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_model_with_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mByobNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_cfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflatten_sequential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:418\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m num_classes_pretrained \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 418\u001b[0m     \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43min_chans\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_filter_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_strict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:158\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pretrained_cfg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid pretrained config, cannot load weights. Use `pretrained=False` for random init.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m load_from, pretrained_loc \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_pretrained_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_from \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    160\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading pretrained weights from state dict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_builder.py:63\u001b[0m, in \u001b[0;36m_resolve_pretrained_source\u001b[0;34m(pretrained_cfg)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _USE_OLD_CACHE:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# prioritized old cached weights if exists and env var enabled\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     old_cache_valid \u001b[38;5;241m=\u001b[39m check_cached_file(pretrained_url) \u001b[38;5;28;01mif\u001b[39;00m pretrained_url \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m old_cache_valid \u001b[38;5;129;01mand\u001b[39;00m hf_hub_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mhas_hf_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnecessary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# hf-hub available as alternate weight source in default_cfg\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     load_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf-hub\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m     pretrained_loc \u001b[38;5;241m=\u001b[39m hf_hub_id\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/timm/models/_hub.py:111\u001b[0m, in \u001b[0;36mhas_hf_hub\u001b[0;34m(necessary)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_hf_hub\u001b[39m(necessary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_hf_hub \u001b[38;5;129;01mand\u001b[39;00m necessary:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# if no HF Hub module installed, and it is necessary to continue, raise error\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _has_hf_hub\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`."
     ]
    }
   ],
   "source": [
    "#checking\n",
    "mobilevitv2_model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k', \n",
    "    pretrained=True, \n",
    "    features_only=True,\n",
    "    output_stride=8\n",
    ")\n",
    "input_tensor = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "# Forward pass\n",
    "output = mobilevitv2_model(input_tensor)\n",
    "print(output[-1].shape)  #[1, 256, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m516\u001b[39m, \u001b[38;5;241m516\u001b[39m, \u001b[38;5;241m516\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape) \n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torchvision/models/segmentation/deeplabv3.py:111\u001b[0m, in \u001b[0;36mASPP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m _res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m--> 111\u001b[0m     _res\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(_res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(res)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# checking\n",
    "model = DeepLabHead(\n",
    "    in_channels=516,  # Adjust in_channels if needed\n",
    "    num_classes=1,  # binary segmentation\n",
    "    atrous_rates=(6,12,18) #from the paper, default (12,24,36)\n",
    ")  \n",
    "input_tensor = torch.randn(1, 516, 516, 516)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileViT_DeepLabV3(\n",
      "  (backbone): MobileViT_Backbone(\n",
      "    (model): FeatureListNet(\n",
      "      (stem): ConvNormAct(\n",
      "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (stages_0): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (stages_1): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (stages_2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitV2Block(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 64, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(64, 129, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 64, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (1): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 64, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(64, 129, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 64, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm1(1, 64, eps=1e-05, affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (stages_3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitV2Block(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (1): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (2): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (3): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm1(1, 96, eps=1e-05, affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (stages_4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (conv1_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2b_kxk): Identity()\n",
      "          (attn): Identity()\n",
      "          (conv3_1x1): ConvNormAct(\n",
      "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "          (attn_last): Identity()\n",
      "          (drop_path): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (1): MobileVitV2Block(\n",
      "          (conv_kxk): ConvNormAct(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_1x1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (transformer): Sequential(\n",
      "            (0): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (1): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "            (2): LinearTransformerBlock(\n",
      "              (norm1): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (attn): LinearSelfAttention(\n",
      "                (qkv_proj): Conv2d(128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (out_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (out_drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.000)\n",
      "              (norm2): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "              (mlp): ConvMlp(\n",
      "                (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (norm): Identity()\n",
      "                (act): SiLU()\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.000)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
      "          (conv_proj): ConvNormAct(\n",
      "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_conv): Identity()\n",
      "    )\n",
      "  )\n",
      "  (deeplab_head): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Output should be [1, 1, 256, 256] for binary segmentation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[75], line 41\u001b[0m, in \u001b[0;36mMobileViT_DeepLabV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x) \u001b[38;5;66;03m#last feature map from mobilevitv2: [1, 256, 8, 8] -> [1,128,32,32]\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeeplab_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torchvision/models/segmentation/deeplabv3.py:111\u001b[0m, in \u001b[0;36mASPP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m _res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m--> 111\u001b[0m     _res\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(_res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(res)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torchvision/models/segmentation/deeplabv3.py:81\u001b[0m, in \u001b[0;36mASPPPooling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39msize, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/functional.py:2507\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2495\u001b[0m         batch_norm,\n\u001b[1;32m   2496\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2505\u001b[0m     )\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2507\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2511\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/hfenv/lib/python3.12/site-packages/torch/nn/functional.py:2475\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2473\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
     ]
    }
   ],
   "source": [
    "# use DeepLabv3 from torchvision?\n",
    "\n",
    "\n",
    "# Define the custom backbone class\n",
    "class MobileViT_Backbone(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(MobileViT_Backbone, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        return features[-4]  # Use the last feature map: [1, 256, 8, 8] -> [1,64,64,64] / [1,128,32,32] or else too small\n",
    "\n",
    "# Load the MobileViT v2 model without the classification head\n",
    "mobilevitv2_model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k', \n",
    "    pretrained=True, \n",
    "    features_only=True\n",
    ")\n",
    "\n",
    "# Create the backbone\n",
    "backbone = MobileViT_Backbone(mobilevitv2_model)\n",
    "\n",
    "# Define the custom model with DeepLabV3 head\n",
    "class MobileViT_DeepLabV3(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(MobileViT_DeepLabV3, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.deeplab_head = DeepLabHead(\n",
    "            in_channels=64,  # Adjust in_channels if needed\n",
    "            num_classes=1, \n",
    "            atrous_rates=(6,12,18) #from the paper, default (12,24,36)\n",
    "        )  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x) #last feature map from mobilevitv2: [1, 256, 8, 8] -> [1,128,32,32]\n",
    "        x = self.deeplab_head(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MobileViT_DeepLabV3(backbone)\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)\n",
    "\n",
    "# Sample input tensor\n",
    "input_tensor = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # Output should be [1, 1, 256, 256] for binary segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as trans\n",
    "# Feature map\n",
    "m2 = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k', \n",
    "    features_only=True, \n",
    "    pretrained=True) \n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(m2)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "m2 = m2.eval()\n",
    "\n",
    "# torchvision transforms module takes PIL image with 3 channels, need to add lines\n",
    "pil_image = trans.ToPILImage()(slice_ADC)\n",
    "x = transforms(pil_image).unsqueeze(0) #torch.Size([1, 3, 256, 256])\n",
    "print(\"x.shape = {}\".format(x.shape))\n",
    "output = m2(x) #list with len=5 tensors\n",
    "\n",
    "#for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 32, 128, 128])\n",
    "    #  torch.Size([1, 64, 64, 64])\n",
    "    #  torch.Size([1, 128, 32, 32])\n",
    "    #  torch.Size([1, 192, 16, 16])\n",
    "    #  torch.Size([1, 256, 8, 8])\n",
    "\n",
    "    #print(o.shape)\n",
    "#m2.feature_info.channels() #[32, 64, 128, 192, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft\n",
    "print(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature map\n",
    "fms = []\n",
    "\n",
    "for feature_map in output:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    gray_scale = gray_scale / feature_map.shape[0] #feature_map.shape[0] = 32,64,128,192,256\n",
    "    fm = gray_scale.data.cpu().numpy()\n",
    "    fms.append(fm)\n",
    "\n",
    "    print(fm.shape)\n",
    "    # the feature map become smaller and contain more information, \"folding\"???\n",
    "    #(128, 128)\n",
    "    #(64, 64)\n",
    "    #(32, 32)\n",
    "    #(16, 16)\n",
    "    #(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "fig.add_subplot(6, 3, 1)\n",
    "ori = plt.imshow(x.squeeze(0)[1,:,:], cmap='Greys_r'); plt.title(\"transforms(ADC)\", fontsize=30)\n",
    "\n",
    "for i in range(len(fms)):\n",
    "    a = fig.add_subplot(6, 3, i+2)\n",
    "    imgplot = plt.imshow(fms[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(\"Layer {} from last {}\".format(len(fms)-i, fms[i].shape), fontsize=30)\n",
    "#plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp output for T2\n",
    "fig = plt.figure(figsize=(30, 50))\n",
    "fig.add_subplot(6, 3, 1)\n",
    "ori = plt.imshow(x.squeeze(0)[1,:,:], cmap='Greys_r'); plt.title(\"transforms(T2)\", fontsize=30)\n",
    "\n",
    "for i in range(len(fms)):\n",
    "    a = fig.add_subplot(6, 3, i+2)\n",
    "    imgplot = plt.imshow(fms[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(\"Layer {} from last {}\".format(len(fms)-i, fms[i].shape), fontsize=30)\n",
    "#plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a different model v1\n",
    "import torchvision.transforms as trans\n",
    "\n",
    "m1 = timm.create_model(\n",
    "    'mobilevit_xxs.cvnets_in1k', \n",
    "    features_only=True, \n",
    "    pretrained=True)\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(m1)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "# torchvision transforms module takes PIL image with 3 channels, need to add lines\n",
    "pil_image = trans.ToPILImage()(slice_T2)\n",
    "x = transforms(pil_image).unsqueeze(0) #torch.Size([1, 3, 256, 256])\n",
    "print(\"x.shape = {}\".format(x.shape))\n",
    "output = m1(x) #list with len=5 tensors\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 16, 128, 128])\n",
    "    #  torch.Size([1, 24, 64, 64])\n",
    "    #  torch.Size([1, 48, 32, 32])\n",
    "    #  torch.Size([1, 64, 16, 16])\n",
    "    #  torch.Size([1, 320, 8, 8])\n",
    "\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp output for T2 in m1\n",
    "fig = plt.figure(figsize=(30, 50))\n",
    "fig.add_subplot(6, 3, 1)\n",
    "ori = plt.imshow(x.squeeze(0)[1,:,:], cmap='Greys_r'); plt.title(\"transforms(T2)\", fontsize=30)\n",
    "\n",
    "for i in range(len(fms)):\n",
    "    a = fig.add_subplot(6, 3, i+2)\n",
    "    imgplot = plt.imshow(fms[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(\"Layer {} from last {}\".format(len(fms)-i, fms[i].shape), fontsize=30)\n",
    "#plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Codes from HF\n",
    "https://huggingface.co/timm/mobilevitv2_050.cvnets_in1k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code from HF (Image Classification)\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "#import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model('mobilevitv2_050.cvnets_in1k', pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "x = transforms(img).unsqueeze(0)\n",
    "output = model(x)  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "print(x.shape) #[1, 3, 256, 256]\n",
    "#print(output)             #shape: [1, 1000]\n",
    "#print(top5_class_indices) #[969, 967, 928, 960, 927]   shape: [1, 5]\n",
    "#print(top5_probabilities) #[24.9318, 12.4587,  8.9054,  6.5909,  5.6044]  shape:[1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Map Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code from HF (Feature Map Extraction)\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 32, 128, 128])\n",
    "    #  torch.Size([1, 64, 64, 64])\n",
    "    #  torch.Size([1, 128, 32, 32])\n",
    "    #  torch.Size([1, 192, 16, 16])\n",
    "    #  torch.Size([1, 256, 8, 8])\n",
    "\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature map\n",
    "processed = []\n",
    "\n",
    "for feature_map in output:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    fm = gray_scale.data.cpu().numpy()\n",
    "    processed.append(fm)\n",
    "\n",
    "    print(fm.shape)\n",
    "    #(128, 128)\n",
    "    #(64, 64)\n",
    "    #(32, 32)\n",
    "    #(16, 16)\n",
    "    #(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(processed)):\n",
    "    a = fig.add_subplot(5, 3, i+1)\n",
    "    imgplot = plt.imshow(processed[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(\"Layer {} from last {}\".format(len(processed)-i, processed[i].shape), fontsize=30)\n",
    "#plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different model v1\n",
    "# Example code from HF (Feature Map Extraction)\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'mobilevit_xxs.cvnets_in1k',\n",
    "    pretrained=True,\n",
    "    features_only=True,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "for o in output:\n",
    "    # print shape of each feature map in output\n",
    "    # e.g.:\n",
    "    #  torch.Size([1, 16, 128, 128])\n",
    "    #  torch.Size([1, 24, 64, 64])\n",
    "    #  torch.Size([1, 48, 32, 32])\n",
    "    #  torch.Size([1, 64, 16, 16])\n",
    "    #  torch.Size([1, 320, 8, 8])\n",
    "\n",
    "    # difference in dim[1]: 32,64,128,192,256 -> 16,24,48,64,320\n",
    "\n",
    "    print(o.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(processed)):\n",
    "    a = fig.add_subplot(5, 3, i+1)\n",
    "    imgplot = plt.imshow(processed[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(\"Layer {} from last {}\".format(len(processed)-i, processed[i].shape), fontsize=30)\n",
    "#plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code from HF (Image Embedding)\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'mobilevitv2_050.cvnets_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear, but still have global pooling?\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) = [1, 256] tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "#output = model.forward_features(transforms(img).unsqueeze(0)) #(1, 256, 8, 8) tensor\n",
    "#output = model.forward_head(output, pre_logits=True) #(1, num_features) tensor\n",
    "\n",
    "plt.imshow(img)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
